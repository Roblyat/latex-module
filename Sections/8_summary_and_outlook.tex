\chapter{Summary and Outlook}

\section{Discussion}

\textbf{K-Domination.}
The K-domination study (Section~5.1.1) quantifies how the number of available
demonstration trajectories influences the two-stage pipeline.
Across all reported metrics, increasing $K$ reduces both (i) the typical error level and
(ii) the variability across dataset seeds, indicating improved generalisation and robustness with
more diverse motion coverage.

\textbf{Stage~1 (DeLaN): learning dynamics and split sensitivity.}
The DeLaN learning curves (Figures~\ref{fig:kdom_delan_train_loss_by_k}
and~\ref{fig:kdom_delan_val_mse_by_k}) summarise the Stage~1 optimisation as a function of
$K$.
Small trajectory sets lead to substantially higher training loss and validation error, together
with markedly larger IQR.
This behaviour is consistent with the fact that the dataset seed determines which trajectories
are selected and how they are split into train/val/test at the trajectory level, which is comparable
to evaluating different ``folds'' of the trajectory pool.
At low $K$, some subsets can miss relevant dynamic regimes, resulting in splits that are harder
to learn and therefore higher validation error; for $K \geq 32$ the curves collapse quickly,
indicating reduced sensitivity to the particular split.

\textbf{Stage~1 (DeLaN): error over motion progress and per-joint balance.}
The progress-aligned RMSE (Figure~\ref{fig:kdom_delan_rmse_progress_by_k}) highlights
that the smallest setting ($K=8$) exhibits pronounced error spikes and large variability along the
trajectory, while increasing $K$ stabilises the error over the full progress range.
Moreover, the per-joint analysis (Figure~\ref{fig:kdom_delan_rmse_per_joint}) shows that for
small $K$ individual joints can dominate the overall error, whereas larger $K$ yields
consistently low and more uniform per-joint errors.
This aligns with the per-joint normalisation used in the Stage~1 loss, but also emphasises that
sufficient trajectory diversity is required for this normalisation to translate into uniform
generalisation across all joints.

\textbf{Stage~2 (LSTM): dependence on $K$ and coupling to Stage~1.}
The residual LSTM results (Figures~\ref{fig:kdom_lstm_train_loss_by_k},
\ref{fig:kdom_lstm_val_loss_by_k}, and~\ref{fig:kdom_lstm_res_rmse_progress_by_k})
indicate that larger $K$ yields lower validation loss and reduced variability.
Since Stage~2 is trained on residuals generated by the frozen Stage~1 model, its achievable
performance is inherently coupled to the quality and coverage of the DeLaN residuals.
Consequently, low $K$ can manifest as larger residual peaks and higher seed sensitivity, whereas
larger $K$ provides a more stable residual learning problem.

\textbf{End-to-end implication.}
The representative overlays (Figures~\ref{fig:kdom_torque_overlay_example}
and~\ref{fig:kdom_residual_overlay_example}) illustrate that the residual learner compensates
systematic deviations of the DeLaN prediction and thereby reduces the final torque error.
Taken together, the K-domination results support the interpretation that a minimum trajectory
count is required before the two-stage pipeline becomes robust to the particular trajectory
selection and split, with diminishing returns as $K$ approaches the full dataset.

% \textbf{Slow movment ISO Norms in Dataset paper signal to noise ration, good pipeline performance on collaboration trajectories
% check that statement in the dataset paper}
